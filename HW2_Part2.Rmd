---
title: "46-926 Homework 2, Part II"
author: "Jingyi Guo, Pittsburgh Campus"
date: "1/28/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE,warning=FALSE}
trainset=read.table("/Users/apple/Desktop/ML/train.csv",sep=",",header=T)
```

## Preparation 1

```{r 1}
fullrow=rep(FALSE,nrow(trainset))
for (i in 1:nrow(trainset))
{
  fullrow[i]=!any(is.na(trainset[i,29:147]))
}
```

Now 40000 logical values(i.e. TRUE or FALSE) are stored in fullrow.

## Preparation 2

```{r 2}
varnames <- c(paste("Ret_", 2:120, sep=""))
fullform = as.formula(paste("Ret_PlusOne ~ ",paste(varnames,collapse="+")))
print(fullform)
```

Now, fullform is a formula that can be used for regression.

## Fit Linear Model

```{r regression}
fitmodel=lm(fullform,data=subset(trainset,fullrow==TRUE))
summary(fitmodel)
```

## Stepwise Variable Selection
```{r stepwise,results='hide'}
finalmod=step(fitmodel,direction="both")
```

(The result is hidden due to length)
90 predictors are retained: Ret_4,Ret_5,Ret_6,Ret_7,
Ret_8,Ret_9,Ret_10,Ret_12,
Ret_13,Ret_14,Ret_15,Ret_16,
Ret_17,Ret_18,Ret_19,Ret_20,
Ret_21,Ret_22,Ret_23,Ret_24,
Ret_25,Ret_26,Ret_27,Ret_28,
Ret_29,Ret_31,Ret_33,Ret_34,
Ret_36,Ret_37,Ret_38,Ret_40,
Ret_41,Ret_42,Ret_43,Ret_44,
Ret_48,Ret_49,Ret_50,Ret_53,
Ret_55,Ret_57,Ret_58,Ret_59,
Ret_60,Ret_61,Ret_62,Ret_64,
Ret_65,Ret_66,Ret_68,Ret_69,
Ret_70,Ret_71,Ret_72,Ret_73,
Ret_74,Ret_75,Ret_77,Ret_78,
Ret_79,Ret_80,Ret_81,Ret_82,
Ret_83,Ret_84,Ret_85,Ret_86,
Ret_87,Ret_89,Ret_90,Ret_91,
Ret_92,Ret_95,Ret_99,Ret_100,
Ret_101,Ret_102,Ret_103,Ret_104,
Ret_105,Ret_107,Ret_109,Ret_113,
Ret_114,Ret_115,Ret_116,Ret_117,
Ret_119,Ret_120


## Residual plot

```{r plot}
plot(as.numeric(finalmod$fit),as.numeric(finalmod$resid),pch=16,xlab="Fitted Values", ylab="Residuals")

plot(as.numeric(finalmod$fit),as.numeric(finalmod$resid),pch=16,xlab="Fitted Values", ylab="Residuals",xlim=c(-0.1,0.1),ylim=c(-0.2,0.2))
```

Comment: There is no significantly prevalent pattern in the plot of residual versus fitted values. However, there are some points for which the residual is quite extreme relative to others.

## Cook's Distance

```{r cook}
cookd=as.numeric(cooks.distance(finalmod))
sort(pf(cookd,91,22299),decreasing=TRUE)[1:5]
```

The largest two Cook's Distance's exceed the median of the F distribution, so they are definitely cause for concern as being too influential.